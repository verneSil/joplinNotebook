netty nio

Netty 是一个高性能网络通信框架，同时它也是比较底层的框架，想要 Netty 支持 Http（超文本传输协议），必须要给它提供相应的编解码器。

面试官 ：为什么要用 Netty 呢？能不能说一下自己的看法。

我 ：因为 Netty 具有下面这些优点，并且相比于直接使用 JDK 自带的 NIO 相关的 API 来说更加易用。
* 自带编解码器解决 TCP 粘包/拆包问题。
* 简单而强大的线程模型。
* 有更高的吞吐量、更低的延迟、更低的资源消耗和更少的内存复制。
* 安全性不错，有完整的 SSL/TLS 以及 StartTLS 支持。
* 自带各种协议栈。

* 统一的 API，支持多种传输类型，阻塞和非阻塞的。
* 简单而强大的线程模型。
* 自带编解码器解决 TCP 粘包/拆包问题。
* 自带各种协议栈。
* 真正的无连接数据包套接字支持。
* 比直接使用 Java 核心 API
* 有更高的吞吐量、更低的延迟、更低的资源消耗和更少的内存复制。
* 安全性不错，有完整的 SSL/TLS 以及 StartTLS 支持。
* 社区活跃
* 成熟稳定，经历了大型项目的使用和考验，而且很多开源项目都使用到了 Netty， 比如我们经常接触的 Dubbo、RocketMQ 等等。


https://blog.csdn.net/yelvgou9995/article/details/106790492


Netty 主要组件
1. channel
	Channel 接口是 Netty 对网络操作抽象类，它除了包括基本的 I/O 操作，如 bind()、connect()、read()、write() 等。
	
	比较常用的Channel接口实现类是NioServerSocketChannel（服务端）和NioSocketChannel（客户端），这两个 Channel 可以和 BIO 编程模型中的ServerSocket以及Socket两个概念对应上。Netty 的 Channel 接口所提供的 API，大大地降低了直接使用 Socket 类的复杂性。
2. eventLoop
	说白了，EventLoop 的主要作用实际就是负责监听网络事件并调用事件处理器进行相关 I/O 操作的处理。
3. ChannelFuture
	etty 是异步非阻塞的，所有的 I/O 操作都为异步的。
	
	因此，我们不能立刻得到操作是否执行成功，但是，你可以通过 ChannelFuture 接口的 addListener() 方法注册一个 ChannelFutureListener，当操作执行成功或者失败时，监听就会自动触发返回结果。
	
	并且，你还可以通过ChannelFuture 的 channel() 方法获取关联的Channel
4. ChannelHandler 和 ChannelPipeline
	下面这段代码使用过 Netty 的小伙伴应该不会陌生，我们指定了序列化编解码器以及自定义的 ChannelHandler 处理消息。
	
* * *
```
        b.group(eventLoopGroup)
                .handler(new ChannelInitializer<SocketChannel>() {
                    @Override
                    protected void initChannel(SocketChannel ch) {
                        ch.pipeline().addLast(new NettyKryoDecoder(kryoSerializer, RpcResponse.class));
                        ch.pipeline().addLast(new NettyKryoEncoder(kryoSerializer, RpcRequest.class));
                        ch.pipeline().addLast(new KryoClientHandler());
                    }
                });
```
* * *

	ChannelHandler 是消息的具体处理器。他负责处理读写操作、客户端连接等事情。

	ChannelPipeline 为 ChannelHandler 的链，提供了一个容器并定义了用于沿着链传播入站和出站事件流的 API 。当 Channel 被创建时，它会被自动地分配到它专属的ChannelPipeline。

	我们可以在 ChannelPipeline 上通过 addLast() 方法添加一个或者多个ChannelHandler ，因为一个数据或者事件可能会被多个 Handler 处理。当一个 ChannelHandler 处理完之后就将数据交给下一个 ChannelHandler 。

5. netty中的nio是一中reactor模型
   ```
   种并发实际说的是并发的不活跃的长连接，并不是并发请求

	典型的后端服务，在逻辑上可以划分为两层，

	跟业务无关的通信层，负责socket连接的创建和管理，负责bind/listen/accept/send/recv...
	通信层上面是业务逻辑层，负责被动响应请求，或主动推送业务消息
	通信层特点：

	都是IO行为，几乎不大消耗CPU
	连接数很多，可能同时有10K甚至100K个TCP连接
	通信协议就那么几种，decode/encode简单
	外部网络是慢速IO，收发一点数据可能要1秒甚至更久
	业务逻辑层特点：

	少量CPU消耗，大部分时间在等待数据库或者其它网络服务返回
	业务逻辑五花八门，逻辑中往往需要调用别的网络服务，如db
	并发请求数，往往小于连接数，10K个连接，可能每秒只有100个请求
	单个业务请求通常很快，毫秒级别，几十毫秒算慢的了
	如果完全采用传统的多线程模型，1个tcp连接对应1个线程，10K个连接需要10K个线程，典型的内存消耗是10G。但是业务逻辑层并发请求往往要小1到2个数量级，每个请求往往只需要100ms以内，所以业务逻辑层需要的线程数，比通信层小2-3个数量级，不需要10K个线程，只要100个甚至10个就够了。

	这种2-3个数量级差距的不匹配，促使了第一代事件驱动的流行，常见的模型，纷纷把通信层剥离出来，用事件驱动的形式取代多线程，但是在业务逻辑层仍然采用多线程模型。几个著名的例子:

	nginx负责通信层，PHP-FPM负责业务逻辑层
	nginx负责通信层，uwsgi负责Python的业务逻辑层
	tomcat nio负责通信层，业务逻辑层扔到线程池里处理
	这些模型都很成功，用几百个甚至区区几十个线程/进程，满足了几万甚至几十万的并发连接。在整个199X年到2010年，这个模型都相当的适用，之后移动互联网兴起，随之也出现越来越多的网络API服务，我们的业务逻辑层，不但要跟内网的网络服务通信，还要跟外网的服务通信，在业务逻辑层也产生了大量的外网网络IO，导致一个请求不能在100ms内完成，可能增加到了500ms甚至几秒钟，其中大部分时间是在等待网络，白白的占用了一个线程等IO。

	如果业务逻辑层也要消耗很多时间等待网络IO，那么它跟通信层的2-3个数量级的线程数量需求这个特性就被打破了，在极端的业务下，他们甚至重新回来1:1这个比例，举个例子，APP的广告服务，一个请求里可能包含3个广告位，每个广告位从20家广告供应商那里获取广告，再选价格最高的返回给APP展示。这里每一个http请求，需要对外发起60个http请求，按照一个100ms算，需要耗时6秒，如果每秒有1000个广告请求，就需要6000个线程才能不积压至服务崩溃。

	所以第二代事件驱动模型应运而生，把业务逻辑也变成事件驱动，彻底消除浪费线程等待IO这个现象。事件驱动有两件常见的外衣，一件是异步回调，另一件是coroutine，近几年有了很多应用：

	Go的goroutine
	Python 3的coroutine
	Kotlin的coroutine
	nodejs的异步回调
	swoole 1的异步回调和swoole 2的coroutine
	erlang/elixir的process也算是coroutine
	VertX的异步回调
	...
	第二代普遍出现的比较晚，而且只有大厂有这个流量需要用到，所以远没有第一代那么普及，coroutine和csp等概念都是几十年前提出的，流行和普及的晚，因此只能算是老年新生事物。

	一小搓培训出身的码农，因为基础差底子差，喜欢把这个当作黑科技来吹，所以才变得有些神秘兮兮了。其实它就是一层窗户纸，轻轻捅破，也就这样了，一点儿都不稀奇。

	真正的门槛和功夫，不是模型本身，是实现这个模型时，处处往死里优化，死抠的那些细节，往往是一般PPT里看不到的。写字人人都会，写出来好不好看，差别就太大了。
   ```




















id: 4ce0603045ec4ed981431d61818d1394
parent_id: c651cf50a0294f15bfa51c27372da183
created_time: 2020-07-07T09:14:31.539Z
updated_time: 2020-07-07T10:15:07.295Z
is_conflict: 0
latitude: 0.00000000
longitude: 0.00000000
altitude: 0.0000
author: 
source_url: 
is_todo: 0
todo_due: 0
todo_completed: 0
source: joplin-desktop
source_application: net.cozic.joplin-desktop
application_data: 
order: 1594113271538
user_created_time: 2020-07-07T09:14:31.539Z
user_updated_time: 2020-07-07T10:15:07.295Z
encryption_cipher_text: 
encryption_applied: 0
markup_language: 1
is_shared: 0
type_: 1